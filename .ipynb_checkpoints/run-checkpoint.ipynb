{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning using AlphaZero methodology\n",
    "\n",
    "Please see https://applied-data.science/blog/how-to-build-your-own-alphazero-ai-using-python-and-keras/ for further notes on the codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First load the core libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "import random\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from game import Game, GameState\n",
    "from agent import Agent\n",
    "from memory import Memory\n",
    "from model import Residual_CNN\n",
    "from funcs import playMatches, playMatchesBetweenVersions\n",
    "\n",
    "import loggers as lg\n",
    "\n",
    "from settings import run_folder, run_archive_folder\n",
    "import initialise\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now run this block to start the learning process\n",
    "\n",
    "This block loops for ever, continually learning from new game data.\n",
    "\n",
    "The current best model and memories are saved in the run folder so you can kill the process and restart from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION NUMBER 1\n",
      "BEST PLAYER VERSION 0\n",
      "SELF PLAYING 5 EPISODES...\n",
      "1 2 3 4 5 \n",
      "\n",
      "len(MEMORY.LTMEMORY): 410\n",
      "MEMORY SIZE: 410\n",
      "ITERATION NUMBER 2\n",
      "BEST PLAYER VERSION 0\n",
      "SELF PLAYING 5 EPISODES...\n",
      "1 2 3 4 5 \n",
      "\n",
      "len(MEMORY.LTMEMORY): 760\n",
      "MEMORY SIZE: 760\n",
      "ITERATION NUMBER 3\n",
      "BEST PLAYER VERSION 0\n",
      "SELF PLAYING 5 EPISODES...\n",
      "1 2 3 4 5 \n",
      "\n",
      "len(MEMORY.LTMEMORY): 1060\n",
      "MEMORY SIZE: 1060\n"
     ]
    }
   ],
   "source": [
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=.      NEW LOG      =*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "\n",
    "env = Game()\n",
    "\n",
    "# If loading an existing neural network, copy the config file to root\n",
    "if initialise.INITIAL_RUN_NUMBER != None:\n",
    "    copyfile(run_archive_folder + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + '/config.py', './config.py')\n",
    "\n",
    "import config\n",
    "\n",
    "######## LOAD MEMORIES IF NECESSARY ########\n",
    "\n",
    "if initialise.INITIAL_MEMORY_VERSION == None:\n",
    "    memory = Memory(config.MEMORY_SIZE)\n",
    "else:\n",
    "    print('LOADING MEMORY VERSION ' + str(initialise.INITIAL_MEMORY_VERSION) + '...')\n",
    "    memory = pickle.load( open( run_archive_folder + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + \"/memory/memory\" + str(initialise.INITIAL_MEMORY_VERSION).zfill(4) + \".p\",   \"rb\" ) )\n",
    "\n",
    "######## LOAD MODEL IF NECESSARY ########\n",
    "\n",
    "# create an untrained neural network objects from the config file\n",
    "current_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) + env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "best_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) +  env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "\n",
    "#If loading an existing neural netwrok, set the weights from that model\n",
    "if initialise.INITIAL_MODEL_VERSION != None:\n",
    "    best_player_version  = initialise.INITIAL_MODEL_VERSION\n",
    "    print('LOADING MODEL VERSION ' + str(initialise.INITIAL_MODEL_VERSION) + '...')\n",
    "    m_tmp = best_NN.read(env.name, initialise.INITIAL_RUN_NUMBER, best_player_version)\n",
    "    current_NN.model.set_weights(m_tmp.get_weights())\n",
    "    best_NN.model.set_weights(m_tmp.get_weights())\n",
    "#otherwise just ensure the weights on the two players are the same\n",
    "else:\n",
    "    best_player_version = 0\n",
    "    best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "\n",
    "#copy the config file to the run folder\n",
    "copyfile('./config.py', run_folder + 'config.py')\n",
    "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "######## CREATE THE PLAYERS ########\n",
    "\n",
    "current_player = Agent('current_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, current_NN)\n",
    "best_player = Agent('best_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, best_NN)\n",
    "#user_player = User('player1', env.state_size, env.action_size)\n",
    "iteration = 0\n",
    "start_time = time.time()\n",
    "for infi in range(10):\n",
    "\n",
    "    iteration += 1\n",
    "    reload(lg)\n",
    "    reload(config)\n",
    "\n",
    "    print('ITERATION NUMBER ' + str(iteration))\n",
    "\n",
    "    lg.logger_main.info('BEST PLAYER VERSION: %d', best_player_version)\n",
    "    print('BEST PLAYER VERSION ' + str(best_player_version))\n",
    "\n",
    "    ######## SELF PLAY ########\n",
    "    print('SELF PLAYING ' + str(config.EPISODES) + ' EPISODES...')\n",
    "    _, memory, _, _ = playMatches(best_player, best_player, config.EPISODES, lg.logger_main, turns_until_tau0 = config.TURNS_UNTIL_TAU0, memory = memory)\n",
    "        \n",
    "    print('\\n')\n",
    "    print(f'len(MEMORY.LTMEMORY): {len(memory.ltmemory)}')\n",
    "    memory.clear_stmemory()\n",
    "    #save memory if it bigger or each 10 minutes\n",
    "    if len(memory.ltmemory) >= config.MEMORY_SIZE or ((time.time()-start_time)/60) > 30:\n",
    "        start_time = time.time()\n",
    "        ######## RETRAINING ########\n",
    "        print('RETRAINING...')\n",
    "        current_player.replay(memory.ltmemory)\n",
    "        print('')\n",
    "\n",
    "#         if iteration % 2 == 0:\n",
    "        pickle.dump( memory, open( run_folder + \"memory/memory\" + str(iteration).zfill(4) + \".p\", \"wb\" ) )\n",
    "\n",
    "        lg.logger_memory.info('====================')\n",
    "        lg.logger_memory.info('NEW MEMORIES')\n",
    "        lg.logger_memory.info('====================')\n",
    "\n",
    "        memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
    "\n",
    "        for s in memory_samp:\n",
    "            current_value, current_probs, _ = current_player.get_preds(s['state'])\n",
    "            best_value, best_probs, _ = best_player.get_preds(s['state'])\n",
    "\n",
    "            lg.logger_memory.info('MCTS VALUE FOR %s: %f', s['playerTurn'], s['value'])\n",
    "            lg.logger_memory.info('CUR PRED VALUE FOR %s: %f', s['playerTurn'], current_value)\n",
    "            lg.logger_memory.info('BES PRED VALUE FOR %s: %f', s['playerTurn'], best_value)\n",
    "            lg.logger_memory.info('THE MCTS ACTION VALUES: %s', ['%.2f' % elem for elem in s['AV']]  )\n",
    "            lg.logger_memory.info('CUR PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  current_probs])\n",
    "            lg.logger_memory.info('BES PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  best_probs])\n",
    "            lg.logger_memory.info('ID: %s', s['state'].id)\n",
    "            lg.logger_memory.info('INPUT TO MODEL: %s', current_player.model.convertToModelInput(s['state']))\n",
    "\n",
    "            s['state'].render(lg.logger_memory)\n",
    "\n",
    "        ######## TOURNAMENT ########\n",
    "        print('TOURNAMENT...')\n",
    "        scores, _, points, sp_scores = playMatches(best_player, current_player, config.EVAL_EPISODES, lg.logger_tourney, turns_until_tau0 = 0, memory = None)\n",
    "        print('\\nSCORES')\n",
    "        print(scores)\n",
    "        print('\\nSTARTING PLAYER / NON-STARTING PLAYER SCORES')\n",
    "        print(sp_scores)\n",
    "        #print(points)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        if scores['current_player'] > scores['best_player'] * config.SCORING_THRESHOLD:\n",
    "            best_player_version = best_player_version + 1\n",
    "            best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "            best_NN.write(env.name, best_player_version)\n",
    "\n",
    "    else:\n",
    "        print('MEMORY SIZE: ' + str(len(memory.ltmemory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'game.GameState'>: it's not the same object as game.GameState",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4fa42f80538d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         if iteration % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"memory/memory\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'game.GameState'>: it's not the same object as game.GameState"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "######## RETRAINING ########\n",
    "print('RETRAINING...')\n",
    "current_player.replay(memory.ltmemory)\n",
    "print('')\n",
    "\n",
    "#         if iteration % 2 == 0:\n",
    "pickle.dump( memory, open( run_folder + \"memory/memory\" + str(iteration).zfill(4) + \".p\", \"wb\" ) )\n",
    "\n",
    "lg.logger_memory.info('====================')\n",
    "lg.logger_memory.info('NEW MEMORIES')\n",
    "lg.logger_memory.info('====================')\n",
    "\n",
    "memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
    "\n",
    "for s in memory_samp:\n",
    "    current_value, current_probs, _ = current_player.get_preds(s['state'])\n",
    "    best_value, best_probs, _ = best_player.get_preds(s['state'])\n",
    "\n",
    "    lg.logger_memory.info('MCTS VALUE FOR %s: %f', s['playerTurn'], s['value'])\n",
    "    lg.logger_memory.info('CUR PRED VALUE FOR %s: %f', s['playerTurn'], current_value)\n",
    "    lg.logger_memory.info('BES PRED VALUE FOR %s: %f', s['playerTurn'], best_value)\n",
    "    lg.logger_memory.info('THE MCTS ACTION VALUES: %s', ['%.2f' % elem for elem in s['AV']]  )\n",
    "    lg.logger_memory.info('CUR PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  current_probs])\n",
    "    lg.logger_memory.info('BES PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  best_probs])\n",
    "    lg.logger_memory.info('ID: %s', s['state'].id)\n",
    "    lg.logger_memory.info('INPUT TO MODEL: %s', current_player.model.convertToModelInput(s['state']))\n",
    "\n",
    "    s['state'].render(lg.logger_memory)\n",
    "\n",
    "######## TOURNAMENT ########\n",
    "print('TOURNAMENT...')\n",
    "scores, _, points, sp_scores = playMatches(best_player, current_player, config.EVAL_EPISODES, lg.logger_tourney, turns_until_tau0 = 0, memory = None)\n",
    "print('\\nSCORES')\n",
    "print(scores)\n",
    "print('\\nSTARTING PLAYER / NON-STARTING PLAYER SCORES')\n",
    "print(sp_scores)\n",
    "#print(points)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "if scores['current_player'] > scores['best_player'] * config.SCORING_THRESHOLD:\n",
    "    best_player_version = best_player_version + 1\n",
    "    best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "    best_NN.write(env.name, best_player_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GameState(test_board, 1)\n",
    "np.random.choice(gs.allowedActions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following panels are not involved in the learning process\n",
    "\n",
    "### Play matches between versions (use -1 for human player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import *\n",
    "from funcs import playMatchesBetweenVersions\n",
    "import loggers as lg\n",
    "\n",
    "\n",
    "playMatchesBetweenVersions(env, 1, 0, 0, 5, lg.logger_tourney, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass a particular game state through the neural network (setup below for Connect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1 -1  0\n",
      "  0  0  0  0  0  0 -1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "from game import *\n",
    "BOARD_SIZE = 9\n",
    "test_board = np.array([0 for i in range(BOARD_SIZE*BOARD_SIZE)])\n",
    "test_board[19] = 1\n",
    "test_board[20] = 1\n",
    "test_board[21] = 1\n",
    "test_board[22] = -1\n",
    "test_board[30] = -1\n",
    "test_board[38] = -1\n",
    "test_board[45] = -1\n",
    "print(test_board)\n",
    "env = Game(BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_player_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agent import User\n",
    "# from game import *\n",
    "# test_board = np.array([0 for i in range(BOARD_SIZE*BOARD_SIZE)])\n",
    "# test_board[19] = 1\n",
    "# test_board[20] = 1\n",
    "# test_board[21] = 1\n",
    "# test_board[22] = -1\n",
    "# test_board[30] = -1\n",
    "# test_board[38] = -1\n",
    "# test_board[45] = -1\n",
    "# print(test_board)\n",
    "# env = Game()\n",
    "# user = User('real_player', env.state_size, env.action_size)\n",
    "# ai = current_player\n",
    "# gs = GameState(test_board, 1)\n",
    "\n",
    "# env.gameState = gs\n",
    "# for r in range(BOARD_SIZE):\n",
    "#         print([env.pieces[str(x)] for x in gs.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "# print(f'player turn: {gs.playerTurn}')\n",
    "# action, pi, MCTS_value, NN_value = ai.act(gs, 0)\n",
    "# # preds = ai.get_preds(gs)\n",
    "# state, value, done, _ = test_game.step(action)\n",
    "# for r in range(BOARD_SIZE):\n",
    "#         print([env.pieces[str(x)] for x in state.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "# # for r in range(BOARD_SIZE):\n",
    "# #         print(['----' if x == 0 else '{0:.2f}'.format(x)\n",
    "# #                for x in \n",
    "# #                preds[1][BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "        \n",
    "# # print(preds) \n",
    "# print(f'player turn: {state.playerTurn}')\n",
    "# state, value, done, _ = test_game.step(14)\n",
    "# test_game.gameState = gs\n",
    "# for r in range(BOARD_SIZE):\n",
    "#         print([env.pieces[str(x)] for x in gs.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "# print()\n",
    "# action, pi, MCTS_value, NN_value = ai.act(gs, 0)\n",
    "# # preds = ai.get_preds(gs)\n",
    "# state, value, done, _ = test_game.step(action)\n",
    "# for r in range(BOARD_SIZE):\n",
    "#         print([env.pieces[str(x)] for x in state.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from agent import User\n",
    "# # test_game\n",
    "# run_version=0\n",
    "# player1version=-1\n",
    "# player2version=0\n",
    "# EPISODES=1\n",
    "# turns_until_tau0=config.TURNS_UNTIL_TAU0\n",
    "# env = Game()\n",
    "# env.gameState = GameState(test_board, 1)\n",
    "# memory = None\n",
    "# goes_first = 1\n",
    "# # scores, memory, points, sp_scores = playMatchesBetweenVersions(test_game, run_version,player1version,player2version,test_episodes,test_logger,turns_until_tau0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset().board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player1 plays as X\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: 1\n",
      "Enter your chosen action: 12\n",
      "<class 'int'>\n",
      "action: %d 12\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', '-', '-', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: -1\n",
      "action: %d 42\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', '-', '-', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: 1\n",
      "Enter your chosen action: 17\n",
      "<class 'int'>\n",
      "action: %d 17\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', '-', 'X', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: -1\n",
      "action: %d 221\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', '-', 'X', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: 1\n",
      "Enter your chosen action: 16\n",
      "<class 'int'>\n",
      "action: %d 16\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', 'X', 'X', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: -1\n",
      "action: %d 2\n",
      "['-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', 'X', 'X', '-', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-']\n",
      "--------------\n",
      "playerTurn: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your chosen action: 18\n",
      "<class 'int'>\n",
      "action: %d 18\n",
      "['-', '-', 'O', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'X', '-', '-']\n",
      "['-', 'X', 'X', 'X', 'X', 'X', 'X', 'O', '-', '-', '-', '-', '-', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-', 'O', '-', '-']\n",
      "['O', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'O', '-', '-', '-']\n",
      "--------------\n",
      "%s WINS! player1\n"
     ]
    }
   ],
   "source": [
    "from agent import User\n",
    "from game import *\n",
    "test_board = np.array([0 for i in range(BOARD_SIZE*BOARD_SIZE)])\n",
    "test_board[19] = 1\n",
    "test_board[20] = 1\n",
    "test_board[21] = 1\n",
    "test_board[22] = -1\n",
    "test_board[30] = -1\n",
    "test_board[38] = -1\n",
    "test_board[45] = -1\n",
    "# print(test_board)\n",
    "env = Game()\n",
    "player1 = User('player1', env.state_size, env.action_size)\n",
    "player2 = current_player\n",
    "env.gameState = GameState(test_board, 1)\n",
    "scores = {player1.name:0, \"drawn\": 0, player2.name:0}\n",
    "sp_scores = {'sp':0, \"drawn\": 0, 'nsp':0}\n",
    "points = {player1.name:[], player2.name:[]}\n",
    "state = env.gameState\n",
    "\n",
    "#     state = env.reset()\n",
    "turns_until_tau0 = config.TURNS_UNTIL_TAU0\n",
    "goes_first = 1\n",
    "done = 0\n",
    "turn = 0\n",
    "player1.mcts = None\n",
    "player2.mcts = None\n",
    "\n",
    "if goes_first == 0:\n",
    "    player1Starts = random.randint(0,1) * 2 - 1\n",
    "else:\n",
    "    player1Starts = goes_first\n",
    "\n",
    "if player1Starts == 1:\n",
    "    players = {1:{\"agent\": player1, \"name\":player1.name}\n",
    "            , -1: {\"agent\": player2, \"name\":player2.name}\n",
    "            }\n",
    "    print(player1.name + ' plays as X')\n",
    "else:\n",
    "    players = {1:{\"agent\": player2, \"name\":player2.name}\n",
    "            , -1: {\"agent\": player1, \"name\":player1.name}\n",
    "            }\n",
    "    print(player2.name + ' plays as X')\n",
    "    print('--------------')\n",
    "\n",
    "for r in range(BOARD_SIZE):\n",
    "    print([env.gameState.pieces[str(x)] for x in env.gameState.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "print('--------------')\n",
    "while done == 0:\n",
    "    turn = turn + 1\n",
    "\n",
    "    #### Run the MCTS algo and return an action\n",
    "    print(f'playerTurn: {state.playerTurn}')\n",
    "    if turn < turns_until_tau0:\n",
    "        action, pi, MCTS_value, NN_value = players[state.playerTurn]['agent'].act(state, 1)\n",
    "    else:\n",
    "        action, pi, MCTS_value, NN_value = players[state.playerTurn]['agent'].act(state, 0)\n",
    "\n",
    "    if memory != None:\n",
    "        ####Commit the move to memory\n",
    "        memory.commit_stmemory(env.identities, state, pi)\n",
    "\n",
    "    print('action: %d', action)\n",
    "\n",
    "    ### Do the action\n",
    "    state, value, done, _ = env.step(action) #the value of the newState from the POV of the new playerTurn i.e. -1 if the previous player played a winning move\n",
    "\n",
    "    for r in range(BOARD_SIZE):\n",
    "        print([env.gameState.pieces[str(x)] for x in env.gameState.board[BOARD_SIZE*r : (BOARD_SIZE*r + BOARD_SIZE)]])\n",
    "    print('--------------')\n",
    "\n",
    "    if done == 1: \n",
    "        if memory != None:\n",
    "            #### If the game is finished, assign the values correctly to the game moves\n",
    "            for move in memory.stmemory:\n",
    "                if move['playerTurn'] == state.playerTurn:\n",
    "                    move['value'] = value\n",
    "                else:\n",
    "                    move['value'] = -value\n",
    "\n",
    "            memory.commit_ltmemory()\n",
    "\n",
    "        if value == 1:\n",
    "            print('%s WINS!', players[state.playerTurn]['name'])\n",
    "#                 logger.info('game over')\n",
    "#             print('len(stmemory): %s, len(ltmemory): %s', str(len(memory.stmemory)), str(len(memory.ltmemory)))\n",
    "            scores[players[state.playerTurn]['name']] = scores[players[state.playerTurn]['name']] + 1\n",
    "            if state.playerTurn == 1: \n",
    "                sp_scores['sp'] = sp_scores['sp'] + 1\n",
    "            else:\n",
    "                sp_scores['nsp'] = sp_scores['nsp'] + 1\n",
    "\n",
    "        elif value == -1:\n",
    "            print('%s WINS!', players[-state.playerTurn]['name'])\n",
    "#             print('len(stmemory): %s, len(ltmemory): %s', str(len(memory.stmemory)), str(len(memory.ltmemory)))\n",
    "            scores[players[-state.playerTurn]['name']] = scores[players[-state.playerTurn]['name']] + 1\n",
    "\n",
    "            if state.playerTurn == 1: \n",
    "                sp_scores['nsp'] = sp_scores['nsp'] + 1\n",
    "            else:\n",
    "                sp_scores['sp'] = sp_scores['sp'] + 1\n",
    "\n",
    "        else:\n",
    "            print('DRAW...')\n",
    "            scores['drawn'] = scores['drawn'] + 1\n",
    "            sp_scores['drawn'] = sp_scores['drawn'] + 1\n",
    "\n",
    "        pts = state.score\n",
    "        points[players[state.playerTurn]['name']].append(pts[0])\n",
    "        points[players[-state.playerTurn]['name']].append(pts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the layers of the current neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_player.model.viewLayers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output a diagram of the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
